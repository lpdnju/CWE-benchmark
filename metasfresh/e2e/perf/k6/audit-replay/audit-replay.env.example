# ==================== Source Database Configuration ====================
# Database connection details for extracting API audit data

SOURCE_DB_HOST=localhost
SOURCE_DB_PORT=15432
SOURCE_DB_NAME=metasfresh
SOURCE_DB_USER=metasfresh
SOURCE_DB_PASSWORD=metasfresh

# ==================== Extraction Filters ====================
# Configure which API requests to extract from the audit table

# ID range (optional - for replaying specific request ranges)
# Leave empty to not filter by ID
MIN_ID=
MAX_ID=

# Time range (ISO 8601 format)
# Leave empty to extract from all time
START_TIME=2025-11-15T00:00:00Z
END_TIME=2025-11-15T23:59:59Z

# Path filter (SQL LIKE pattern)
# Examples:
#   /api/v2/%              - All API v2 endpoints
#   /api/v2/bpartner%      - All BPartner endpoints
#   %invoice%              - All invoice-related endpoints
PATH_FILTER=%/v2/%

# Status filter
# Values: Empfangen, Verarbeitet, Fehler
# Usually you want Verarbeitet (successfully executed requests)
STATUS_FILTER=Verarbeitet

# Maximum number of requests to extract
MAX_REQUESTS=10000

# Headers to exclude from replay (comma-separated)
# These are auto-generated and should not be replayed
EXCLUDE_HEADERS=Host,Connection,Content-Length,User-Agent

# Include expected response data for comparison
# Set to true to compare actual vs expected responses
INCLUDE_RESPONSES=true

# ==================== Target Instance Configuration ====================
# Where to replay the extracted requests

# Base URL of the target metasfresh instance
# Examples:
#   http://localhost:8282/api/v2  - Local development
#   http://app:8282/api/v2        - Docker container
#   https://prod.example.com/api/v2 - Production instance
TARGET_BASE_URL=http://localhost:8282/api/v2

# Authentication token for the target instance
# If set, this will replace the original Authorization header
# Leave empty to use original tokens (may fail if tokens expired)
TARGET_AUTH_TOKEN=

# ==================== Load Test Configuration ====================
# K6 load test parameters

# Number of virtual users (concurrent connections)
VUS=1

# Execution mode - choose ONE of the following:
# 1. DURATION mode (for load testing - loops requests continuously)
DURATION=300s

# 2. ITERATIONS mode (for exact replay - runs each request once)
# Set to:
#   0     - Use DURATION mode (default)
#   auto  - Run exactly as many iterations as extracted requests (recommended for exact replay)
#   N     - Run exactly N iterations
# Example: If you extracted 100 requests and set ITERATIONS=auto, k6 will execute exactly 100 requests and stop
ITERATIONS=0

# Think time between requests (in seconds)
# Set to 0 for no delay
THINK_TIME=1

# Replay mode
# Values:
#   sequential - Replay requests in chronological order
#   random     - Replay requests in random order
REPLAY_MODE=sequential

# Compare response bodies with expected values
# Set to true to validate response content (may slow down test)
COMPARE_RESPONSES=false

# Replace authorization token with TARGET_AUTH_TOKEN
# Set to false to keep original tokens
REPLACE_AUTH_TOKEN=true

# ==================== Output Configuration ====================
# Where to save extracted data and results
#
# NOTE: By default, output files are automatically saved to a timestamped run folder:
#   ./runs/YYYY-MM-DD_HH-MM-SS/extracted-api-audit.json
#   ./runs/YYYY-MM-DD_HH-MM-SS/audit-replay-results.json
#   ./runs/YYYY-MM-DD_HH-MM-SS/audit-replay.env
#
# Only uncomment these if you want to override the default locations:
# EXTRACTED_DATA_FILE=./my-custom-path/extracted-api-audit.json
# RESULTS_FILE=./my-custom-path/audit-replay-results.json
# HTML_REPORT=./my-custom-path/audit-replay-report.html

# ==================== Operational Flags ====================
# Control which steps to execute

# Skip extraction step (use existing EXTRACTED_DATA_FILE)
SKIP_EXTRACTION=false

# Skip replay step (only extract data)
SKIP_REPLAY=false

# ==================== Debug Flags ====================
# Debugging and troubleshooting options

# Show SQL queries during extraction
DEBUG=false

# Show SQL query and exit (for debugging filters)
SHOW_SQL=false

# ==================== Example Configurations ====================

# Example 1: Extract last 24 hours of BPartner requests and replay locally
# START_TIME=$(date -u -d '1 day ago' +%Y-%m-%dT%H:%M:%SZ)
# END_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)
# PATH_FILTER=/api/v2/bpartner%
# TARGET_BASE_URL=http://localhost:8282/api/v2
# VUS=10
# DURATION=60s

# Example 2: Extract specific time window and replay with high load
# START_TIME=2025-11-15T08:00:00Z
# END_TIME=2025-11-15T09:00:00Z
# PATH_FILTER=/api/v2/%
# TARGET_BASE_URL=http://staging:8282/api/v2
# VUS=100
# DURATION=600s

# Example 3: Extract all invoice requests from production and replay to staging
# PATH_FILTER=%invoice%
# MAX_REQUESTS=5000
# TARGET_BASE_URL=https://staging.example.com/api/v2
# TARGET_AUTH_TOKEN=your-staging-token-here
# VUS=50
# DURATION=300s
# COMPARE_RESPONSES=true
